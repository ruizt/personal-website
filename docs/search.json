[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Trevor D. Ruiz",
    "section": "",
    "text": "Hello, I’m an Assistant Professor in the Statistics Department at Cal Poly, San Luis Obispo. Most of my work is informed by an interest in applications of statistical methods in the sciences. Here you can find information about my teaching and research activity."
  },
  {
    "objectID": "index.html#professional-appointments",
    "href": "index.html#professional-appointments",
    "title": "Trevor D. Ruiz",
    "section": "Professional appointments",
    "text": "Professional appointments\nCalifornia Polytechnic State University, San Luis Obispo\nAssistant Professor | 2023-present\nUniversity of California, Santa Barbara\nVisiting Assistant Professor | 2020-2023"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Trevor D. Ruiz",
    "section": "Education",
    "text": "Education\nOregon State University | Corvallis, OR\nPh.D. & M.S. Statistics | 2015-2020\nReed College | Portland, OR\nB.A. Philosophy | 2007-2011"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Model selection for high-dimensional time series\nFrom the perspective of practice, high-dimensional time series — serial observations of a large number of measurements — can be modeled using methods that essentially reduce to regression techniques. Though highly convenient, the model parametrization for this approach is dense, requiring a minimum of \\(p^2\\) parameters for a \\(p\\)-variate time series. Many of these parameters are negligibly small or contribute minimally to model fit; filtering out those parameters at the model fitting stage and selecting a reduced model is a challenge. Standard methods underperform in practice due to dependence in the data.\nI have a series of works exploring empirical methods of selecting an appropriate parameter subset for vector autoregressive models. Early methods adapted a resampling-based approach from the ordinary regression setting more or less directly (T. Ruiz et al. 2019, 2020) and explored computational scaling on distributed systems (Balasubramanian et al. 2018, 2020). My dissertation research refined the methodology through empirical experiments and considered its application to models for count-valued data (T. D. Ruiz 2020). Based on these experiments, I proposed selecting parameters identified with a user-specified minimum frequency across several validation subsamples (T. D. Ruiz, Bhattacharyya, and Emerson 2023). This method has applications in estimating causal networks from time series data, such as ecological interaction networks, functional connectivity in the brain, or macroeconomic relationships.\n\n\nPoisson models for time series of multivariate counts\nPoisson mixtures with autoregressive conditional means provide a convenient framework for modeling count-valued multivariate time series due to their close connection with generalized linear models. For these models, the canonical link yields a process with conditional means that are log-linear in past values. This allows for both positive and negative serial correlations, but can result in superexponentiation of the mean over time unless parameters are chosen carefully. However, the unconditional process moments are not analytically tractable, so identifying the exact subset of the parameter space on which the process is stable is a challenge.\nI developed a constraint on the positive serial correlation structure for the log-linear model that is sufficient to ensure bounded first and second process moments (T. D. Ruiz, Bhattacharyya, and Emerson 2022). This has implications for simulation as well as for understanding model limitations. Future work might relax the constraint, establish necessary and sufficient stability conditions for the log-linear model, or propose an alternative parametrization that allows both positive and negative serial correlations but avoids the superexponentiation problem.\n\n\nAgricultural epidemiology\nAgricultural epidemics driven by aerially-dispersed pathogens exhibit spatially anisotropic patterns of expansion from epicenters due to varying windspeeds and landscape features. Covariates that potentially explain patterns of anisotropy are readily available from public data sources, and thus allow for several approaches to modeling disease spread to potentially aid in identifying effective management interventions.\nI worked on collaborations that developed two modeling frameworks. The first was a network approach applied to a specific pathosystem comprising hop farms in Western Oregon: disease levels obtained from a census of growing locations along with spatiotemporally-integrated wind intensity along the directions defined by every pair of locations was used to predict disease levels in the subsequent month using nonlinear generalized regression models (Gent et al. 2017; Gent, Bhattacharyya, and Ruiz 2019). The second was a general framework for modeling continental-scale epidemics with multiple epicenters based only on time-of-first-occurrence data from a spatially sparse monitoring network of sentinel growing plots (Ojwang et al. 2021).\n\n\n\n\n\n\n\n\nPublications and other works cited\n\nBalasubramanian, Mahesh, Trevor D Ruiz, Brandon Cook, Mr Prabhat, Sharmodeep Bhattacharyya, Aviral Shrivastava, and Kristofer E Bouchard. 2020. “Scaling of Union of Intersections for Inference of Granger Causal Networks from Observational Data.” In 2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS), 264–73. IEEE. https://doi.org/10.1109/IPDPS47924.2020.00036.\n\n\nBalasubramanian, Mahesh, Trevor Ruiz, Brandon Cook, Sharmodeep Bhattacharyya, Aviral Shrivastava, Kristofer Bouchard, et al. 2018. “Optimizing the Union of Intersections LASSO (UoI-LASSO) and Vector Autoregressive (UoI-VAR) Algorithms for Improved Statistical Estimation at Scale.” arXiv Preprint arXiv:1808.06992. https://doi.org/10.48550/arXiv.1808.06992.\n\n\nGent, David H, Sharmodeep Bhattacharyya, and Trevor Ruiz. 2019. “Prediction of Spread and Regional Development of Hop Powdery Mildew: A Network Analysis.” Phytopathology 109 (8): 1392–1403. https://doi.org/10.1094/PHYTO-12-18-0483-R.\n\n\nGent, David H, Sharmodeep Bhattacharyya, Trevor Ruiz, Megan Twomey, and Sierra Wolfenbarger. 2017. “A Network Model to Predict Spread and Mesoscale Level Development of Hop Powdery Mildew.” In 2017 APS Annual Meeting. APSNET.\n\n\nOjwang, Awino ME, Trevor Ruiz, Sharmodeep Bhattacharyya, Shirshendu Chatterjee, Peter S Ojiambo, and David H Gent. 2021. “A General Framework for Spatio-Temporal Modeling of Epidemics with Multiple Epicenters: Application to an Aerially Dispersed Plant Pathogen.” Frontiers in Applied Mathematics and Statistics, 72. https://doi.org/10.3389/fams.2021.721352.\n\n\nRuiz, Trevor D. 2020. “Estimation and Sparse Selection of Conditional Probability Models for Vector Time Series.” https://ir.library.oregonstate.edu/concern/graduate_thesis_or_dissertations/k0698g13s.\n\n\nRuiz, Trevor D, Sharmodeep Bhattacharyya, and Sarah C Emerson. 2022. “A Graphical Sufficient Condition for the Stability of First-Order Log-Linear Poisson Generalized Vector Autoregressive Processes.” Preprint Available at SSRN 4283477. https://doi.org/10.2139/ssrn.4283477.\n\n\n———. 2023. “Sparse Estimation of Parameter Support Sets for Generalized Vector Autoregressions by Resampling and Model Aggregation.” arXiv Preprint arXiv:2307.09684. https://doi.org/10.48550/arXiv.2307.09684.\n\n\nRuiz, Trevor, Mahesh Balasubramanian, Kristofer E Bouchard, and Sharmodeep Bhattacharyya. 2019. “Sparse, Low-Bias, and Scalable Estimation of High Dimensional Vector Autoregressive Models via Union of Intersections.” arXiv Preprint arXiv:1908.11464. https://doi.org/10.48550/arXiv.1908.11464.\n\n\nRuiz, Trevor, Sharmodeep Bhattacharyya, Mahesh Balasubramanian, and Kristofer Bouchard. 2020. “Sparse and Low-Bias Estimation of High Dimensional Vector Autoregressive Models.” In Learning for Dynamics and Control, 55–64. PMLR. http://proceedings.mlr.press/v120/ruiz20a.html."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "I consider myself a lifelong learner. At some point, it became natural to teach, both as a vehicle for further learning and as a means of giving back by helping to train future practitioners and scientists.\nMuch of my experience teaching statistics is concentrated around methods, applications, and data science, but I have broad interests in teaching across and beyond the discipline. I have designed a few courses; you can see an example here. One of my more significant teaching projects involved extensive work on a capstone course sequence at UCSB that combined project-based learning with training on “soft” skills; you can read about that here. A full list of courses I’ve taught follows; I’m happy to share materials for any of these for instructional purposes on request."
  },
  {
    "objectID": "teaching.html#interests",
    "href": "teaching.html#interests",
    "title": "Teaching",
    "section": "",
    "text": "I consider myself a lifelong learner. At some point, it became natural to teach, both as a vehicle for further learning and as a means of giving back by helping to train future practitioners and scientists.\nMuch of my experience teaching statistics is concentrated around methods, applications, and data science, but I have broad interests in teaching across and beyond the discipline. I have designed a few courses; you can see an example here. One of my more significant teaching projects involved extensive work on a capstone course sequence at UCSB that combined project-based learning with training on “soft” skills; you can read about that here. A full list of courses I’ve taught follows; I’m happy to share materials for any of these for instructional purposes on request."
  },
  {
    "objectID": "teaching.html#courses",
    "href": "teaching.html#courses",
    "title": "Teaching",
    "section": "Courses",
    "text": "Courses\n\nCal Poly\n\nProbability theory [STAT425]\nFall 2023\nBasic probability theory, combinatorial methods, independence, conditional and marginal probability, probability models for random phenomena, random variables, probability distributions, distributions of functions of random variables, mathematical expectation, covariance and correlation, conditional expectation.\n\n\n\nUC Santa Barbara\n\nData science capstone [PSTAT197] [website]\nWinter 2022, Spring 2022, Fall 2022, Winter 2023, Spring 2023\nA preparatory course in data science topics and collaborative research skills (PSTAT197A/CMPSC190DD, offered fall term) and two experiential learning courses in which students work in teams on interdisciplinary projects sponsored by an external partner and advised by a technical specialist (PSTAT197B-C/CMPSC190DE-DF, offered winter and spring terms). Project teams establish a group contract outlining basic agreements pertaining to the collaboration and agree on outputs to produce for the sponsor by the end of the project – typically software, documentation, and a presentation. The course sequence culminates with a public showcase of student work.\n\n\nData science concepts and analysis [PSTAT100] [website]\nSpring 2021, Winter 2022, Spring 2022, Spring 2023\nA hands-on introduction to data science intended for intermediate-level students from any discipline with some exposure to probability and basic computing skills, but few or no upper-division courses in statistics or computer science. The course introduces central concepts in statistics – such as sampling variation, uncertainty, and inference – in an applied setting together with techniques for data exploration and analysis. Applications emphasize end-to-end data analyses.\n\n\nStatistical machine learning [PSTAT131/231]\nWinter 2021, Spring 2021\nStatistical Machine Learning is used to discover patterns and relationships in large data sets. Topics include: data exploration, classification and regression tress, random forests, clustering and association rules, building predictive models focusing on model selection, and model comparison and performance evaluation. Emphasis is on concepts, methods and data analysis, and students are expected to complete a significant class project, individual or team based, using real-world data.\n\n\nRegression analysis [PSTAT126]\nSummer 2021, Fall 2021\nA first course in linear regression for statistics majors covering both theory and applications with a strong emphasis on statistical computing and visualization techniques in R using tidyverse programming. Tools for reproducible analysis are also introduced. The course covers the linear model in matrix form, parameter estimation and interpretation, residual diagnostics, statistical inference, case influence statistics and outlier detection, common data transformations, categorical variables and interaction terms, and model selection and prediction.\n\n\nProbability and statistics [PSTAT120B]\nFall 2020, Winter 2021, Summer 2021, Fall 2021\nDistribution of sample mean and sample variance; t, chi-squared and F distributions; summarizing data by statistics and graphs; estimation theory for single samples: sufficiency, efficiency, consistency, method of moments, maximum likelihood; hypothesis testing: likelihood ratio test; confidence intervals.\n\n\n\nOregon State University\n\nIntroduction to statistical methods [ST351-352]\nSpring 2018, Summer 2018\nStudy designs, descriptive statistics, collecting and recording data, probability distributions, sampling distributions for means and proportions, hypothesis testing and confidence intervals for means and proportions in one- and two-sample inference, and chi-square tests."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Student projects",
    "section": "",
    "text": "I’m enthusiastic about supporting undergraduate research. If you’re a student and you’re interested in research opportunities or have a project idea, or if you’re a researcher looking for student collaborators, please feel free to get in touch."
  },
  {
    "objectID": "projects.html#past-projects",
    "href": "projects.html#past-projects",
    "title": "Student projects",
    "section": "Past projects",
    "text": "Past projects\n\nData science capstones\nWhile at UCSB I co/led instruction of a year-long capstone1 in 2021-2022 and 2022-2023. The goal of the capstone was to engage undergraduate students in collaborative research. In the two years I oversaw the course we had 28 projects spanning a wide range of domain and industry applications.2 I had the good fortune of working with many talented students and dedicated partnering labs and companies, several of whom extended their research efforts in various ways beyond the scope of the class.\nIn 2022, two students extended a project on visualizing oceanographic data by developing outreach materials for public science education and engagement and gave a presentation on data storytelling at the sponsoring organization’s annual conference (Gupta et al. 2022). In 2023, two capstone groups presented their research during a poster session at the SIGKDD conference’s Southern California Data Science Day — one project used self-supervised learning to identify impact risk due to wildfires based on geography, fire, and location attributes (Umsted et al. 2023), and the other explored an early detection system for identifying case onset of influenza-like illness based on biometric data from wearable devices (Rumsey et al. 2023). Another notable project from this year involved constructing 3D models of bees using photogrammetry (Spasibenko et al. 2023)."
  },
  {
    "objectID": "projects.html#footnotes",
    "href": "projects.html#footnotes",
    "title": "Student projects",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRead the sequence description on my teaching page.↩︎\nA full project list can be found here.↩︎"
  }
]