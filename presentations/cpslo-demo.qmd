---
title: "Interval estimation"
subtitle: "Cal Poly Teaching Demo"
author: "Trevor Ruiz"
date: "November 17, 2022"
editor: visual
format:
  revealjs: 
    incremental: true
    slide-number: true
    callout-icon: false
---

# Setting the stage

## Audience and background

***Audience:*** undergraduate students taking a first course in statistics.

***Possible texts:*** Using R for Introductory Statistics by John Verzani; Introductory Statistics with Randomization and Simulation by Diez *et al.*

***Prior sessions:*** we would have already covered...

-   sampling concepts and inferential thinking

-   elementary data visualizations and summary statistics

-   point estimation for the mean and variance

-   sampling distributions

# Interval estimation for a population parameter

## Today's goal

## Motivating example

::: callout-tip
## Question

*How hard is it to juggle* $K$ *objects?*
:::

. . .

If the general population can typically manage at most $\theta$ objects:

-   larger numbers $K >\theta$ are hard

-   smaller numbers $K < \theta$ are easy

## Quick survey

::: columns
::: {.column width="50%"}
Show of hands, how many of you can juggle...

-   0 but no more

-   1 but no more

-   2 but no more

-   3 but no more

-   4 +
:::

::: {.column width="50%"}
::: callout-caution
## Caveat

This is a ***convenience sample*** -- a collection of easy-to-obtain observations.

-   can't assume it's representative of any broader population

-   so sample statistics are not reliable estimates
:::
:::
:::

. . .

*Let's imagine we can collect a representative sample.*

## What's typical?

A few common ways to define the "typical number":

-   ($\theta$ = population mean) the average number the general population can juggle

-   ($\theta$ = population median) the 'middle' number the general population can juggle

. . .

::: callout-tip
## Terminology

These are examples of different ***population parameters***.
:::

## Notation

-   $X$ is the ***variable of interest***

    -   *e.g.*, greatest number of objects a person can juggle

-   $f(x)$ is the ***population density*** of values of $X$

    -   precise interpretation depends on whether $X$ is discrete or continuous, but roughly: frequency of the value $x$ among the population

-   $\theta$ is a ***population parameter*** of interest

-   $X_1, \dots, X_n$ are observations for a ***random sample***

-   $\hat{\theta}$ is a ***point estimator*** of the population parameter

## Review: point estimation

Often $\hat{\theta}$ is simply the sample analogue of $\theta$: for instance, as we saw before, the sample mean is a point estimator of the population mean.

```{r}
#| fig-width: 10
#| fig-height: 3
#| fig-cap: Estimate of the population mean (left) using the sample mean (right) of 50 independent observations.

library(tidyverse)
theme_set(theme(text = element_text(size = 20)))

fig_pop <- tibble(x = 0:10) %>%
  mutate(fx = dpois(x, lambda = 1.5)) %>%
  ggplot(aes(x = x, y = fx)) +
  geom_segment(aes(x = x, xend = x, y = 0, yend = fx)) +
  geom_point() +
  scale_x_continuous(breaks = 0:10) +
  scale_y_sqrt() +
  geom_vline(xintercept = 1.5,
             color = 'red', 
             linetype = 'dashed') +
  geom_text(aes(x = 1.5, 
                y = 0.32, 
                label = 'theta == 1.5',
                hjust = 0.1),
            parse = T,
            color = 'red',
            nudge_x = 0.3) +
  labs(y = 'f(x)',
       title = 'population') +
  geom_hline(yintercept = 0)

set.seed(111222)
nobs <- 50
samp <- rpois(nobs, lambda = 1.5)
fig_samp <- tibble(x = samp) %>%
  group_by(x) %>%
  count() %>%
  mutate(p = n/nobs) %>%
  ggplot(aes(x = x, y = p)) +
  geom_segment(aes(x = x, xend = x, y = 0, yend = p)) +
  geom_vline(xintercept = mean(samp),
             linetype = 'dashed',
             color = 'red') +
  
  geom_point() +
  scale_x_continuous(breaks = 0:10) +
  scale_y_sqrt() +
  geom_text(aes(x = mean(samp), 
                y = 0.3, 
                label = paste('hat(theta) == ', mean(samp)),
                hjust = 1),
            parse = T,
            color = 'red',
            nudge_x = -0.1) +
  labs(y = expr(paste(hat(f), '(x)', sep = '')),
       title = 'sample') +
  geom_hline(yintercept = 0)

pop_viz_df <- mvtnorm::rmvnorm(n = 5000, mean = rep(0, 2)) %>%
  as_tibble() %>%
  bind_cols(type = c(rep('nsamp', 5000 - nobs), rep('samp', nobs))) 

pop_viz <- pop_viz_df %>%
  ggplot(aes(x = V1, y = V2)) +
  geom_point(aes(alpha = type, color = type)) +
  theme_void() +
  guides(color = guide_none(), alpha = guide_none()) +
  scale_color_manual(values = c('#000000', '#9B0707'))

gridExtra::grid.arrange(fig_pop, fig_samp, pop_viz, nrow = 1)
```

## ... but it could have been different

```{r}
#| fig-width: 10
#| fig-height: 6
#| fig-cap: Point estimates for the population mean (still $\theta = 1.5$) from six distinct samples.
set.seed(111222)
nobs <- 50
nsamp <- 8

sim_df <- tibble(id = paste('sample', 1:nsamp, sep = ' ')) %>%
  mutate(samp = map(id, ~ rpois(nobs, lambda = 1.5)),
         sampmean = map(samp, mean),
         sampvar = map(samp, var)) %>%
  unnest(c(samp, sampmean, sampvar)) %>%
  group_by(id, samp) %>%
  summarize(prop = n()/nobs, 
            sampmean = unique(sampmean),
            sampvar = unique(sampvar),
            .groups = 'drop')

sim_df %>%
  ggplot(aes(x = samp, y = prop)) +
  geom_point() +
  geom_segment(aes(x = samp, xend = samp, y = 0, yend = prop)) +
  geom_vline(aes(xintercept = sampmean),
             linetype = 'dashed',
             color = 'red') +
  geom_hline(yintercept = 0) +
  facet_wrap(~id, nrow = 2) +
  scale_x_continuous(breaks = 0:10) +
  scale_y_sqrt(limits = c(0, 0.5)) +
  geom_text(aes(x = sampmean, 
                y = 0.45, 
                label = paste('hat(theta) == ', sampmean),
                hjust = 0),
            parse = T,
            color = 'red',
            nudge_x = 0.1) +
  labs(x = 'x', 
       y = expr(paste(hat(f), '(x)', sep = '')))
```

## Sampling variation

Even though estimates are pretty similar (and also close to $\theta$!) for most samples, they do move around a little.

. . .

```{r}
#| fig-height: 1
#| fig-width: 8
#| fig-align: center
sim_df %>%
  group_by(id) %>%
  summarize(thetahat = unique(sampmean)) %>%
ggplot(aes(x=thetahat, y=0)) +
  geom_line(size=1) +
  geom_point(shape = 108, size = 5) +
  geom_text(aes(label=id),
            hjust=0, 
            angle = 45, 
            vjust=0, 
            check_overlap = T,
            size = 4)+
  geom_text(aes(label=round(thetahat, 2)),hjust=.5, vjust=2, size = 4) +
  theme_void()  +
  theme(axis.line.y=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank(),
          axis.title.y=element_blank(),
          panel.grid.minor.y=element_blank(),
          panel.grid.major.y=element_blank()) +
  xlim(c(1.2, 1.8))
```

. . .

::: callout-tip
## Idea

What if instead of a single best guess, we calculated a range based on how much we sampling variation we expect in the point estimate?
:::

## Interval estimates

::: callout-tip
## Concept

An ***interval estimate*** is a range of values for a population parameter.
:::

. . .

```{r}
#| fig-width: 8
#| fig-height: 3
#| fig-cap: Two hypothetical intervals -- interval 1 covers the parameter and interval 2 misses.
tibble(interval = paste('interval', 2:1, sep = ' '),
       lwr = c(1, 0.6), 
       upr = c(5, 3.6),
       pop = rep(4.11, 2),
       y = c(-0.2, 0.2)) %>%
  ggplot(aes(y = y)) +
  geom_errorbarh(aes(xmin = lwr, xmax = upr, height = 0.1)) +
  ylim(c(-1, 1)) + 
  xlim(c(-2, 8)) +
  geom_segment(aes(x = pop, xend = pop, y = -0.6, yend = 0.6),
               linetype = 'dashed', color = 'red') +
  geom_text(aes(x = pop, y = 0.5, label = 'theta'), 
            parse = T, 
            color = 'red', 
            nudge_x = 0.2, 
            nudge_y = 0.2,
            size = 6) +
   geom_text(aes(x = lwr, label = 'hat(theta)[LO]'), 
            parse = T, 
            nudge_x = 0.2, 
            nudge_y = 0.2,
            size = 6) +
   geom_text(aes(x = upr, label = 'hat(theta)[HI]'), 
            parse = T, 
            nudge_x = 0.2, 
            nudge_y = 0.2,
            size = 6) +
  theme_void() +
  geom_text(aes(x = 7, label = interval),
            size = 6)
```

## Constructing intervals

A general method of construction for an interval estimate is:

1.  start with a point estimate $\hat{\theta}$

2.  based on its sampling distribution, choose an appropriate $a, b$ and compute

    $$
    (\hat{\theta} - a, \hat{\theta} + b)
    $$

. . .

::: callout-tip
## Terminology

If $a = b$, we say the interval is ***symmetric.***
:::

## Helpful and unhelpful intervals

If we say that the average number of objects the general population can juggle is between 0 and 10 objects...

-   almost certainly correct

-   but not informative

. . .

If on the other hand we say 1.3-1.4...

-   informative estimate

-   but more likely to be mistaken

. . .

*So just how wide should we make the interval?*

## A design principle: coverage

We should be able to say how often a particular *method of interval estimation* produces a 'correct' result. This is known as "coverage".

. . .

::: callout-tip
## Key concept

The ***coverage*** of an interval estimator is the proportion of samples for which the interval covers the population parameter.
:::

. . .

So if an interval has a coverage of 0.86, that means that the method by which it was constructed produces a 'correct' result (*i.e.,* covers $\theta$) for 86% of samples.

## Interval for the mean

::: callout-caution
## Problem statement

Based on the sample mean $\hat{\theta}$, can we find a symmetric interval for the population mean $\theta$ that achieves a coverage of $1 - \alpha$?
:::

. . .

The classical solution is based on the $T$ statistic $T(\hat{\theta}) = \frac{\hat{\theta} - \theta}{SE(\hat{\theta})}$.

1.  $T(\hat{\theta})$ has a $t_{n - 1}$ sampling distribution (approximately)
2.  $P(-t^{\alpha/2} < T(\hat{\theta}) < t^{\alpha/2}) = 1 - \alpha$ for $t$-quantiles $t^{\alpha/2}$

. . .

::: callout-caution
## Reminder

A ***standard error*** is an estimate of the standard deviation of the sampling distribution. For the sample mean, $SE(\hat{\theta}) = \sqrt{S^2/n}$.
:::

## Interval for the mean {.smaller}

The event that the $T$ statistic is between two quantiles is equivalent to the event that the population parameter is covered by the endpoints:

$$
-t^{\alpha/2} < \underbrace{\frac{\hat{\theta} - \theta}{SE(\hat{\theta})}}_{T(\hat{\theta})} < t^{\alpha/2}
\quad\Longleftrightarrow\quad
\underbrace{\hat{\theta} - t^{\alpha/2} SE(\hat{\theta})}_{\hat{\theta} - a} < \theta < \underbrace{\hat{\theta} + t^{\alpha/2} SE(\hat{\theta})}_{\hat{\theta} + b}
$$

. . .

So the probabilities are also equal and therefore:

$$
P\left(\hat{\theta} - t^{\alpha/2} SE(\hat{\theta}) < \theta < \hat{\theta} + t^{\alpha/2} SE(\hat{\theta})\right) = 1 - \alpha
$$

. . .

In other words, the interval $\hat{\theta} \pm t^{\alpha/2}SE(\hat{\theta})$ covers $\theta$ with probability $1 - \alpha$.

## Calculating intervals {.smaller}

```{r}
#| echo: true
set.seed(111222)
n <- 50
x <- rpois(n, lambda = 1.5)
```

These intervals are easy to compute:

1.  Calculate the sample mean $\hat{\theta}$and the sample variance $S^2$

    ```{r}
    #| echo: true
    c(mean(x), var(x))
    ```

2.  Compute $SE(\hat{\theta}) = \sqrt{\frac{S^2}{n}}$

    ```{r}
    #| echo: true
    sqrt(var(x)/n)
    ```

3.  Find the $t^{\alpha/2}$ quantile (with $n - 1$ degrees of freedom)

    ```{r}
    #| echo: true
    qt(0.025, df = n - 1, lower.tail = F)
    ```

4.  Calculate the interval

    ```{r}
    #| echo: true
    c(1.76 - 2.01*0.189, 1.76 + 2.01*0.189)
    ```

## Comparing coverages

```{r}
#| fig-cap: Calculated intervals with two coverages -- 50% intervals (left) and 80% intervals(right).
#| fig-width: 8
#| fig-height: 5

set.seed(111222)
nobs <- 50
nsamp <- 8

tibble(id = paste('sample', 1:nsamp, sep = ' ')) %>%
  mutate(samp = map(id, ~ rpois(nobs, lambda = 1.5)),
         ttest.lo = map(samp, ~t.test(.x, conf.level = 0.5)),
         ttest.hi = map(samp, ~t.test(.x, conf.level = 0.8)),
         coverage.50 = map(ttest.lo, ~.x$conf.int),
         coverage.80 = map(ttest.hi, ~.x$conf.int)) %>%
  select(id, contains('coverage')) %>%
  pivot_longer(-id) %>%
  unnest(value) %>%
  mutate(bound = rep(c('lwr', 'upr'), 8*2)) %>%
  pivot_wider(id_cols = c(id, name), 
              names_from = bound, 
              values_from = value) %>%
  mutate(covers = as.logical((lwr < 1.5)*(upr > 1.5))) %>%
  ggplot(aes(y = id)) +
  geom_errorbarh(aes(xmin = lwr, xmax = upr, color = covers)) +
  geom_vline(xintercept = 1.5, linetype = 'dashed', color = 'red') +
  theme_minimal() +
    facet_wrap(~name) +
  labs(y = '') +
  guides(color = guide_none())
```

## Interval interpretation

::: callout-note
## Terminology

Statisticians equate coverage with the degree of confidence they have in their estimates: if an interval covers 86% of samples, then we can be 86% confident it is correct.

For this reason interval coverage is more commonly called a ***confidence level.***
:::

The standard interval interpretation is:

> *With* $100\times (1 - \alpha)\%$ *confidence, the population mean is estimated to be between* $\hat{\theta}_{LO}$ *and* $\hat{\theta}_{HI}$*.*

## Incorrect interpretation

::: callout-caution
## Common mistake

It is ***not*** accurate to say $\theta$ is between the endpoints with probability $1 - \alpha$.
:::

. . .

Why not? Because $\theta$ is a parameter, not a random variable.

## Interval width

::: callout-tip
## Uncertainty quantification

The width of an interval conveys the degree of uncertainty associated with an estimate.
:::

The width of the interval for the mean is:

$$
\left[\hat{\theta} + t^{\alpha/2} SE(\hat{\theta})\right] - \left[\hat{\theta} - t^{\alpha/2} SE(\hat{\theta})\right]
= 2t^{\alpha/2}SE(\hat{\theta})
= 2\times t^{\color{maroon}{\alpha/2}}\times \sqrt{\frac{\color{purple}{S^2}}{\color{teal}{n}}}
$$

. . .

What do you think will happen if we...

-   lower the [coverage]{style="color:maroon;"}? (hint: already saw this)

-   collect [more data]{style="color:teal;"}?

-   sample from a population with [more variability]{style="color:purple;"}?

## Checking our answers

::: panel-tabset
### Change sample size

```{r}
set.seed(111222)
nobs <- 50
nsamp <- 25

tibble(id = paste('sample', 1:nsamp, sep = ' '),
       idnum = 1:nsamp) %>%
  mutate(sampsize.50 = map(id, ~ rpois(nobs, lambda = 1.5)),
         sampsize.100 = map(id, ~ rpois(2*nobs, lambda = 1.5))) %>%
  pivot_longer(contains('sampsize'), values_to = 'data') %>%
  mutate(ttest = map(data, ~t.test(.x, conf.level = 0.85)),
         ci = map(ttest, ~.x$conf.int)) %>%
  unnest(ci) %>%
  mutate(bound = rep(c('lwr', 'upr'), nsamp*2)) %>%
  pivot_wider(id_cols = c(id, idnum, name), 
              names_from = bound, 
              values_from = ci) %>%
  mutate(covers = as.logical((lwr < 1.5)*(upr > 1.5))) %>%
  ggplot(aes(y = reorder(id, idnum))) +
  geom_errorbarh(aes(xmin = lwr, xmax = upr, color = covers)) +
  geom_vline(xintercept = 1.5, linetype = 'dashed', color = 'red') +
  theme_minimal() +
    facet_wrap(~name) +
  labs(y = '', x = expr(hat(theta))) +
  guides(color = guide_none())

```

### Change population variance

```{r}
set.seed(111222)
nobs <- 50
nsamp <- 25

tibble(id = paste('sample', 1:nsamp, sep = ' '),
       idnum = 1:nsamp) %>%
  mutate(var.hi = map(id, ~ rpois(nobs, lambda = 1.5) + 
                        round(rnorm(nobs, 0, 0.5))),
         var.lo = map(id, ~ rpois(2*nobs, lambda = 1.5))) %>%
  pivot_longer(contains('var'), values_to = 'data') %>%
  mutate(ttest = map(data, ~t.test(.x, conf.level = 0.85)),
         ci = map(ttest, ~.x$conf.int)) %>%
  unnest(ci) %>%
  mutate(bound = rep(c('lwr', 'upr'), nsamp*2)) %>%
  pivot_wider(id_cols = c(id, idnum, name), 
              names_from = bound, 
              values_from = ci) %>%
  mutate(covers = as.logical((lwr < 1.5)*(upr > 1.5))) %>%
  ggplot(aes(y = reorder(id, idnum))) +
  geom_errorbarh(aes(xmin = lwr, xmax = upr, color = covers)) +
  geom_vline(xintercept = 1.5, linetype = 'dashed', color = 'red') +
  theme_minimal() +
    facet_wrap(~name) +
  labs(y = '', x = expr(hat(theta))) +
  guides(color = guide_none())
```
:::

## Takeaways

1.  Interval estimates are a range of values rather than a single number.
2.  Constructed from a point estimator and knowledge of its sampling distribution.
3.  Interval estimators are constructed to achieve a specified *coverage*: proportion of samples for which the interval includes the population parameter.
4.  Given a fixed coverage, the width of an interval communicates the degree of uncertainty about the estimate.
